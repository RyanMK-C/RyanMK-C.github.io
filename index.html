<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Controle Gestual e Eye Tracking</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      width: 100%;
      font-family: Arial, sans-serif;
      background-color: hsl(210, 50%, 50%);
      user-select: none;
    }
    #video {
      position: fixed;
      width: 320px;
      height: 240px;
      bottom: 15px;
      right: 15px;
      object-fit: cover;
      border-radius: 12px;
      border: 2px solid lime;
      transform: scaleX(-1);
      z-index: 10;
    }
    #hud {
      position: fixed;
      top: 15px;
      left: 15px;
      background: rgba(0,0,0,0.5);
      padding: 15px 20px;
      border-radius: 12px;
      color: white;
      z-index: 20;
      display: flex;
      flex-direction: column;
      gap: 12px;
      width: 220px;
    }
    #feedbackCanvas {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      pointer-events: none;
      z-index: 5;
    }
    #status {
      position: fixed;
      bottom: 10px;
      left: 10px;
      color: white;
      background: rgba(0,0,0,0.6);
      padding: 6px 10px;
      border-radius: 8px;
      font-size: 14px;
      z-index: 20;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="feedbackCanvas"></canvas>

  <div id="hud">
    <label for="brightnessRange">Brilho:</label>
    <input type="range" id="brightnessRange" min="0.2" max="2" step="0.01" value="1" />
  </div>

  <div id="status">Carregando câmera...</div>

  <!-- TensorFlow.js + Handpose -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

  <!-- WebGazer.js para eye tracking -->
  <script src="https://cdn.jsdelivr.net/npm/webgazer/dist/webgazer.min.js"></script>

  <script>
    (async () => {
      const status = document.getElementById('status');
      const brightnessRange = document.getElementById('brightnessRange');
      const video = document.getElementById('video');
      const canvas = document.getElementById('feedbackCanvas');
      const ctx = canvas.getContext('2d');

      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;

      // Setup camera
      async function setupCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user' },
          audio: false,
        });
        video.srcObject = stream;
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            video.play();
            resolve();
          };
        });
      }

      // Load handpose model
      status.textContent = 'Carregando câmera...';
      await setupCamera();
      status.textContent = 'Carregando modelo...';
      await tf.setBackend('webgl');
      const model = await handpose.load();
      status.textContent = 'Modelo carregado. Buscando mão...';

      // WebGazer para eye tracking
      webgazer.setRegression('ridge')  // ridge ou polynomial
        .setGazeListener(function(data, elapsedTime) {
          if (data) {
            const x = data.x;
            const y = data.y;
            drawEyeTrackingPoint(x, y);
          }
        });

      // Iniciar o WebGazer
      webgazer.begin();
      webgazer.showPredictionPoints(true); // Mostrar pontos de previsão no canvas

      // Função para desenhar o ponto de visão (tracking dos olhos)
      function drawEyeTrackingPoint(x, y) {
        ctx.clearRect(0, 0, canvas.width, canvas.height); // Limpa a tela
        ctx.fillStyle = 'red';
        ctx.beginPath();
        ctx.arc(x, y, 10, 0, 2 * Math.PI);
        ctx.fill();
      }

      // Atualiza status
      webgazer.setGazeListener(function(data) {
        if (data) {
          status.textContent = `Gaze X: ${data.x.toFixed(2)} Y: ${data.y.toFixed(2)}`;
        } else {
          status.textContent = 'Aguardando rastreamento...';
        }
      });

      // Atualizar brilho com slider
      document.body.style.filter = `brightness(${brightnessRange.value})`;
      brightnessRange.addEventListener('input', () => {
        document.body.style.filter = `brightness(${brightnessRange.value})`;
      });
      
      // Aqui pode adicionar mais interações como troca de cor, etc.
    })();
  </script>
</body>
</html>
