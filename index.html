<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Controle Gestual com Hand Tracking</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      width: 100%;
      font-family: Arial, sans-serif;
      background-color: #282828;
      overflow: hidden;
      user-select: none;
    }

    #video {
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: cover;
      z-index: 1;
      transform: scaleX(-1); /* Espelha a imagem da câmera */
    }

    #feedbackCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 2;
      pointer-events: none;
    }

    #tutorial {
      position: absolute;
      top: 10%;
      right: 20px;
      background-color: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 15px;
      border-radius: 8px;
      width: 250px;
      font-size: 14px;
      z-index: 10;
    }

    #status {
      position: absolute;
      bottom: 10px;
      left: 10px;
      color: white;
      background: rgba(0, 0, 0, 0.6);
      padding: 6px 10px;
      border-radius: 8px;
      font-size: 14px;
      z-index: 10;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="feedbackCanvas"></canvas>

  <div id="tutorial">
    <h3>Instruções:</h3>
    <p><strong>Pinça</strong>: Aperte os dedos indicador e polegar para aumentar o brilho.</p>
    <p><strong>Deslizar</strong>: Movimente a mão para alterar o brilho da tela.</p>
  </div>

  <div id="status">Carregando câmera...</div>

  <!-- TensorFlow.js + Handpose -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

  <script>
    async function setupCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' },
        audio: false,
      });
      video.srcObject = stream;

      return new Promise(resolve => {
        video.onloadedmetadata = () => {
          video.play();
          resolve(video);
        };
      });
    }

    async function detectHands(video, model) {
      const canvas = document.getElementById('feedbackCanvas');
      const ctx = canvas.getContext('2d');
      const status = document.getElementById('status');

      const videoWidth = video.videoWidth || 640;
      const videoHeight = video.videoHeight || 480;

      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;

      // Função para limpar o canvas
      function clearCanvas() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }

      // Função para desenhar os pontos da mão
      function drawLandmarks(landmarks) {
        clearCanvas();
        ctx.fillStyle = 'lime';

        // Ajuste de escala para o canvas
        const videoWidth = video.videoWidth || 640;
        const videoHeight = video.videoHeight || 480;

        for (const point of landmarks) {
          let x = videoWidth - point[0];  // Espelhar X para combinar com o vídeo espelhado
          let y = point[1];

          // Escalar para o tamanho do canvas
          x = (x / videoWidth) * canvas.width;
          y = (y / videoHeight) * canvas.height;

          ctx.beginPath();
          ctx.arc(x, y, 10, 0, 2 * Math.PI);
          ctx.fill();
        }
      }

      // Função para calcular distância entre dois pontos
      function distance(p1, p2) {
        return Math.hypot(p1[0] - p2[0], p1[1] - p2[1]);
      }

      let currentBrightness = 1;  // Brilho inicial
      document.body.style.filter = `brightness(${currentBrightness})`;

      // Detectar gestos de pinça
      let isPinching = false;
      const PINCH_THRESHOLD = 30;

      async function loop() {
        const predictions = await model.estimateHands(video, true);

        if (predictions.length > 0) {
          const hand = predictions[0];
          const landmarks = hand.landmarks;

          // Desenhar os pontos da mão
          drawLandmarks(landmarks);

          // Detectar gesto de pinça (distância entre polegar e indicador)
          const pinchDistance = distance(landmarks[8], landmarks[4]);

          if (pinchDistance < PINCH_THRESHOLD && !isPinching) {
            isPinching = true;
            // Aumentar brilho
            currentBrightness = Math.min(2, currentBrightness + 0.1);  // Limita até o máximo de 2x brilho
            document.body.style.filter = `brightness(${currentBrightness})`;
            status.textContent = `Brilho: ${currentBrightness.toFixed(2)}`;
          } else if (pinchDistance >= PINCH_THRESHOLD && isPinching) {
            isPinching = false;
          }

        } else {
          clearCanvas();
          status.textContent = 'Nenhuma mão detectada';
        }

        requestAnimationFrame(loop);
      }

      loop();
    }

    async function init() {
      const status = document.getElementById('status');
      status.textContent = 'Carregando modelo...';

      // Carregar o modelo Handpose
      await tf.setBackend('webgl');
      const model = await handpose.load();

      status.textContent = 'Modelo carregado. Detectando mãos...';

      // Configuração da câmera
      const video = await setupCamera();

      // Iniciar a detecção de mãos
      detectHands(video, model);
    }

    init();
  </script>
</body>
</html>
